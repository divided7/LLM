# LLM & KG
## Preface
大语言模型已经能很好的实现问答、文本输出，但其输出结果可能有时候并没有足够的依据，因此存在一个 **RAG(Retrieval-Augmented Generation)** 技术，通过在生成回答之前先检索相关知识，从而使生成的内容更加可靠，适用于问答系统、文档生成、客户支持等任务。这样的相关知识可以是文档，也可以是知识图谱。

因此，本研究旨在融合LLM和知识图谱。

## LLM

## RAG
### RAG的优势
* 增强的知识覆盖：即使生成模型本身没有直接学习到特定信息，通过检索可以查找到相关信息。
* 动态更新：由于信息可以实时检索，知识库或数据库中的更新信息可以即时被使用，模型无需重新训练。
* 提升生成的准确性和可信度：在生成阶段引入检索信息，使生成内容更具参考价值，有助于回答事实性问题。
### RAG的应用
* 问答系统：提供更精准的回答，尤其适合需要基于外部知识库回答的问题。
* 文档生成：将多个段落或文档中的内容组织成流畅的文本。
* 客户支持和推荐系统：根据问题或查询检索相关信息，并生成响应，以便提供个性化的回答。
### RAG的实现
* RAG通常通过两步分离的管道实现：首先检索模型（如DPR）获取相关文档，然后生成模型（如BERT、T5）生成最终回答。
* 在实践中，可以使用诸如Hugging Face Transformers库中的实现，将RAG模型部署在本地或云端。
## Knowledge Graph
