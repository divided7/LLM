# LLM & KG

## Preface
大语言模型已经能很好的实现问答、文本输出，但其输出结果可能有时候并没有足够的依据，因此利用 **RAG(Retrieval-Augmented Generation)** 技术，通过在生成回答之前先检索相关知识，从而使生成的内容更加可靠，适用于问答系统、文档生成、客户支持等任务。这样的相关知识可以是文档，也可以是知识图谱。

本研究旨在融合LLM和知识图谱: LLM赋能知识图谱的构建，知识图谱赋能LLM的准确性。

## LLM

## Knowledge Graph
### 三元组数据获取
https://colab.research.google.com/drive/1scsACHDW_1hjFq3KDSfsOuLgPJGx8ox9?usp=sharing

## RAG
### RAG的优势
* 增强的知识覆盖：即使生成模型本身没有直接学习到特定信息，通过检索可以查找到相关信息。
* 动态更新：由于信息可以实时检索，知识库或数据库中的更新信息可以即时被使用，模型无需重新训练。
* 提升生成的准确性和可信度：在生成阶段引入检索信息，使生成内容更具参考价值，有助于回答事实性问题。
### RAG的应用
* 问答系统：提供更精准的回答，尤其适合需要基于外部知识库回答的问题。
* 文档生成：将多个段落或文档中的内容组织成流畅的文本。
* 客户支持和推荐系统：根据问题或查询检索相关信息，并生成响应，以便提供个性化的回答。
### RAG的实现
* RAG通常通过两步分离的管道实现：首先检索模型（如DPR）获取相关文档，然后生成模型（如BERT、T5）生成最终回答。
* 在实践中，可以使用诸如Hugging Face Transformers库中的实现，将RAG模型部署在本地或云端。

## LLM x Knowledge Graph
### 知识图谱作为检索源
检索节点和关系：可以将知识图谱作为检索来源，将用户的查询与知识图谱中的实体和关系匹配，并检索出相关的子图。检索到的结构化信息可以直接传递给生成模型，以提供有根据的生成内容。
结合文本检索：如果查询较为复杂，RAG系统可以先进行文档检索，再在匹配到的文档中提取出相关实体和关系。生成模型可以在文档和知识图谱的双重支持下生成更加丰富的回答。
### 知识图谱与生成模型的融合
结构化信息输入：生成模型可以利用知识图谱中的节点属性和关系，作为额外的上下文信息。例如，在问答过程中，生成模型可以参考实体的相关属性值，并基于这些属性生成答案。
关系路径增强：如果知识图谱中存在查询实体的多层关系（如“公司—产品—功能”路径），生成模型可以利用这种路径信息，生成更具逻辑性的回答。例如，模型可以沿着关系路径“推理”出答案，而不仅仅依赖无结构的文档信息。
### 推理与动态更新
推理：知识图谱可以通过规则和逻辑推理扩展已有知识。例如，对于具有关系推理功能的知识图谱（如有推理引擎的图数据库），可以根据现有的关系推导出新的知识，并将这些推理结果提供给生成模型。
动态更新：RAG系统可以从知识图谱中实时检索和生成最新的信息，无需重新训练模型，从而实现动态知识的更新和准确性保持。
### RAG与知识图谱的混合架构
图谱嵌入：利用图嵌入技术将知识图谱的结构信息转换为数值向量。将知识图谱中的实体和关系向量化后，可以直接与查询向量匹配，以此检索相关知识。之后再将匹配到的知识作为生成模型的输入，生成符合语境的内容。
多模态融合：结合文档检索和知识图谱检索的结果，通过多模态数据增强生成效果。例如，首先检索到的文本段落和知识图谱内容可以一起作为生成模型的输入，帮助模型从多个角度生成回答。
